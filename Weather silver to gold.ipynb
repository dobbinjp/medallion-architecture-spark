{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\r\n",
        "import delta"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rawfolder = \"abfss://raw@dobbinsdatalake.dfs.core.windows.net/weatherbit/*.json\"\r\n",
        "# schema_file = \"abfss://raw@dobbinsdatalake.dfs.core.windows.net/weatherbit/2023_07_21_16_00_23_UTC.json\"\r\n",
        "silver_folder = \"abfss://silver@dobbinsdatalake.dfs.core.windows.net/delta/weather_silver/weather\"\r\n",
        "gold_folder = \"abfss://gold@dobbinsdatalake.dfs.core.windows.net/delta/weather_gold/weather\""
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate from weather_silver.weather table (this goes back 30 days so we don't aggregate the entire silver layer)\r\n",
        "\r\n",
        "df = spark.sql(f\"\"\"\r\n",
        "    with readings as (\r\n",
        "        SELECT date_trunc('DAY',timestampadd(HOUR, -6, to_timestamp(ob_time))) AS ObDateST,\r\n",
        "            double((1.8 * temp) + 32) as AirTemp,\r\n",
        "            double(gust) * 2.237 as gust --mph\r\n",
        "        from weather_silver.weather\r\n",
        "        where date_trunc('DAY',timestampadd(HOUR, -6, to_timestamp(ob_time))) >= date_add(current_timestamp(), -30)\r\n",
        "    )\r\n",
        "    select ObDateST, \r\n",
        "        round(min(AirTemp),1) as min_temp,\r\n",
        "        round(max(AirTemp),1) as max_temp,\r\n",
        "        round(avg(AirTemp),1) as avg_temp,\r\n",
        "        round(max(gust)) as max_gust\r\n",
        "    from readings\r\n",
        "    group by ObDateST\"\"\")"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initial write\r\n",
        "# df.write.format(\"delta\").mode(\"overwrite\").save(gold_folder)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_df = delta.DeltaTable.forPath(spark, gold_folder)\r\n",
        "\r\n",
        "(delta_df\r\n",
        "    .alias(\"delta_wx\")\r\n",
        "    .merge(df.alias(\"updated_wx\"),\r\n",
        "        \"delta_wx.ObDateST == updated_wx.ObDateST\")\r\n",
        "        .whenMatchedUpdate(set = {\"ObDateST\":\"updated_wx.ObDateST\", \"min_temp\":\"updated_wx.min_temp\", \"max_temp\":\"updated_wx.max_temp\", \"avg_temp\":\"updated_wx.avg_temp\", \"max_gust\":\"updated_wx.max_gust\"})\r\n",
        "        .whenNotMatchedInsert(values = {\"ObDateST\":\"updated_wx.ObDateST\", \"min_temp\":\"updated_wx.min_temp\", \"max_temp\":\"updated_wx.max_temp\", \"avg_temp\":\"updated_wx.avg_temp\", \"max_gust\":\"updated_wx.max_gust\"})\r\n",
        "        .execute()\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "create database if not exists weather_gold;"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "create table if not exists weather_gold.weather_obs_summary\r\n",
        "using delta\r\n",
        "location 'abfss://gold@dobbinsdatalake.dfs.core.windows.net/delta/weather_gold/weather'"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%sql\r\n",
        "\r\n",
        "# describe history weather_gold.weather_obs_summary"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# version as ints or longs\r\n",
        "# df_changes = spark.read.format(\"delta\") \\\r\n",
        "#   .option(\"readChangeFeed\", \"true\") \\\r\n",
        "#   .option(\"startingVersion\", 19) \\\r\n",
        "#   .option(\"endingVersion\", 22) \\\r\n",
        "#   .table(\"weather_gold.weather_obs_summary\")"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display(df_changes.sort(F.col(\"ObDateST\").desc()))\r\n",
        "# df_changes.createOrReplaceTempView(\"changes\")"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}